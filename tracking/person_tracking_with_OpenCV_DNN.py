import cv2
from picamera2 import Picamera2
from libcamera import Transform
from gpiozero import PWMOutputDevice, DigitalOutputDevice, DistanceSensor
from time import sleep

# === GPIO í•€ ì„¤ì • ===
PWMA = PWMOutputDevice(18)
AIN1 = DigitalOutputDevice(22) #ì™¼ ë°”í€´ í›„ì§„
AIN2 = DigitalOutputDevice(27) #ì™¼ ë°”í€´ ì „ì§„
PWMB = PWMOutputDevice(23)
BIN1 = DigitalOutputDevice(25) #ì˜¤ë¥¸ ë°”í€´ í›„ì§„
BIN2 = DigitalOutputDevice(24) #ì˜¤ë¥¸ ë°”í€´ ì „ì§„

# === ì´ˆìŒíŒŒ ì„¼ì„œ ì„¤ì • ===
front_sensor = DistanceSensor(echo=10, trigger=9, max_distance=2.0)
left_sensor = DistanceSensor(echo=17, trigger=4, max_distance=2.0)
right_sensor = DistanceSensor(echo=8, trigger=7, max_distance=2.0)



# === ëª¨í„° ì œì–´ í•¨ìˆ˜ ===
def stop_motors():
    PWMA.value = 0.0
    PWMB.value = 0.0

def move_forward():
    AIN1.value, AIN2.value = 0, 1
    BIN1.value, BIN2.value = 0, 1
    PWMA.value = 0.6
    PWMB.value = 0.6

def turn_left():
    AIN1.value, AIN2.value = 1, 0
    BIN1.value, BIN2.value = 0, 1
    PWMA.value = 0.3
    PWMB.value = 0.3

def turn_right():
    AIN1.value, AIN2.value = 0, 1
    BIN1.value, BIN2.value = 1, 0
    PWMA.value = 0.3
    PWMB.value = 0.3

def soft_turn_left():
    AIN1.value, AIN2.value = 0, 0
    BIN1.value, BIN2.value = 0, 1
    PWMA.value = 0.6
    PWMB.value = 0.6

def soft_turn_right():
    AIN1.value, AIN2.value = 0, 1
    BIN1.value, BIN2.value = 0, 0
    PWMA.value = 0.6
    PWMB.value = 0.6

# === ì¥ì• ë¬¼ íšŒí”¼ í•¨ìˆ˜ ===
def obstacle_avoidance():
    global last_avoid  # <- ì „ì—­ë³€ìˆ˜ ì‚¬ìš© ëª…ì‹œ
    front = front_sensor.distance * 100
    left = left_sensor.distance * 100
    right = right_sensor.distance * 100

    print(f"ê±°ë¦¬ - ì •ë©´: {front:.1f}cm, ì™¼ìª½: {left:.1f}cm, ì˜¤ë¥¸ìª½: {right:.1f}cm")

    if front < 20:
        if left < 10:
            print("â†©ï¸ ì™¼ìª½ íšŒí”¼")
            turn_left()
            last_avoid = "left"
        elif right < 10:
            print("â†ªï¸ ì˜¤ë¥¸ìª½ íšŒí”¼")
            turn_right()
            last_avoid = "right"
        elif left >= 10 and right >= 10:
            print("ëŒ€ìƒê³¼ ì ì •ê±°ë¦¬ ìœ ì§€")
            stop_motors()
            sleep(5)

        

        # ì›ë˜ ë°©í–¥ ë³µì›
        # if last_avoid == "left":
        #     print("â†ªï¸ ì˜¤ë¥¸ìª½ ë³µê·€")
        #     turn_right()
        #     sleep(1)
        # elif last_avoid == "right":
        #     print("â†©ï¸ ì™¼ìª½ ë³µê·€")
        #     turn_left()
        #     sleep(1)

        # print("â¬†ï¸ ì „ì§„ ë³µê·€")
        # move_forward()
        # sleep(0.5)
        # return True

    elif left < 20 and right >= 20:
        print("ğŸ ì™¼ìª½ì— ì¥ì• ë¬¼ â†’ ì˜¤ë¥¸ìª½ íœ˜ì–´ì„œ ì§„í–‰")
        soft_turn_right()
        sleep(0.3)
        return True

    elif right < 20 and left >= 20:
        print("ğŸ ì˜¤ë¥¸ìª½ì— ì¥ì• ë¬¼ â†’ ì™¼ìª½ íœ˜ì–´ì„œ ì§„í–‰")
        soft_turn_left()
        sleep(0.3)
        return True

    elif left < 20 and right < 20:
        print("â— ì–‘ì˜† ì¥ì• ë¬¼ â†’ ì •ë©´ í™•ì¸ í›„ ì •ì§€ ë˜ëŠ” íšŒí”¼")
        if front > 20:
            print("â¬†ï¸ ì „ì§„ ê°€ëŠ¥")
            move_forward()
        else:
            print("ğŸ›‘ ì–‘ì˜† + ì •ë©´ ì¥ì• ë¬¼ â†’ ë©ˆì¶¤")
            stop_motors()
        sleep(0.3)
        return True

    return False  # íšŒí”¼ í•„ìš” ì—†ìŒ

classNames = {0: 'background',
              1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus',
              7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant',
              13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat',
              18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear',
              24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag',
              32: 'tie', 33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard',
              37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove',
              41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle',
              46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon',
              51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange',
              56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut',
              61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed',
              67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse',
              75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven',
              80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock',
              86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', 90: 'toothbrush'}

def id_class_name(class_id, classes):
    return classes.get(class_id, "Unknown")

def main():
    camera = Picamera2()
    camera.configure(camera.create_preview_configuration(
        main={"format": 'XRGB8888', "size": (640, 480)},
        transform=Transform(hflip=1, vflip=1) # ìˆ˜í‰, ìˆ˜ì§ ë’¤ì§‘ê¸° ë™ì‹œì— ì ìš© (180ë„ íšŒì „ íš¨ê³¼)
    ))
    
    try:
        camera.start()
        print("âœ… Picamera2ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ğŸš¨ğŸš¨ğŸš¨ ì—ëŸ¬: Picamera2ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤! ğŸš¨ğŸš¨ğŸš¨")
        print(f"  - ì—ëŸ¬ ë©”ì‹œì§€: {e}")
        print("  1. ì¹´ë©”ë¼ ëª¨ë“ˆì´ ì œëŒ€ë¡œ ì—°ê²°ë˜ì–´ ìˆë‚˜ìš”?")
        print("  2. 'sudo raspi-config'ì—ì„œ ì¹´ë©”ë¼ ì˜µì…˜ì´ í™œì„±í™”ë˜ì–´ ìˆë‚˜ìš”?")
        print("  3. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì´ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ê³  ìˆì§€ëŠ” ì•Šë‚˜ìš”?")
        print("  4. ë¼ì¦ˆë² ë¦¬ íŒŒì´ë¥¼ ì¬ë¶€íŒ…í•´ë³´ì…¨ë‚˜ìš”?")
        return

    try:
        model = cv2.dnn.readNetFromTensorflow('/home/robot/market-with-following-basket/tracking/models/frozen_inference_graph.pb',
                                      '/home/robot/market-with-following-basket/tracking/models/ssd_mobilenet_v2_coco_2018_03_29.pbtxt')
        
        if model.empty():
            print("ğŸš¨ ì—ëŸ¬: DNN ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œì™€ íŒŒì¼ ì†ìƒ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return
        last_state = "stop"
        while True:
            keyValue = cv2.waitKey(1)
        
            if keyValue == ord('q') :
                break
            
            image = camera.capture_array()
            image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)
            
            image_height, image_width, _ = image.shape

            model.setInput(cv2.dnn.blobFromImage(image, size=(300, 300), swapRB=True))
            output = model.forward()

            person_detected = False
            
            front = front_sensor.distance * 100
            left = left_sensor.distance * 100
            right = right_sensor.distance * 100
            print(f"ê±°ë¦¬ - ì •ë©´: {front:.1f}cm, ì™¼ìª½: {left:.1f}cm, ì˜¤ë¥¸ìª½: {right:.1f}cm")

            for detection in output[0, 0, :, :]:
                confidence = detection[2]
                class_id = int(detection[1])
                
                if confidence > .5 and class_id == 1: # ì‹ ë¢°ë„ê°€ 0.5 ì´ìƒì´ê³ , í´ë˜ìŠ¤ IDê°€ 1 (ì‚¬ëŒ)ì¸ ê²½ìš°
                    class_name=id_class_name(class_id,classNames)

                    person_detected = True

                    box_x_min = int(detection[3] * image_width)
                    box_y_min = int(detection[4] * image_height)
                    box_x_max = int(detection[5] * image_width)
                    box_y_max = int(detection[6] * image_height)
                    box_center_x = int((box_x_min + box_x_max) / 2)

                    cv2.rectangle(image, (box_x_min, box_y_min), (box_x_max, box_y_max), (0, 0, 200), thickness=2)
                    cv2.line(image, (box_center_x, box_y_min), (box_center_x, box_y_max), (200, 0, 0), thickness=2)
                    print(f"box_y_min: {box_y_min}, box_y_max: {box_y_max}")
                          
                    if box_y_min < 50:
                        stop_motors()
                        print("ëŒ€ìƒê³¼ ì ì •ê±°ë¦¬ ìœ ì§€")
                    
                    elif left < 20:
                        soft_turn_right()
                        print("ì™¼ìª½ì— ì¥ì• ë¬¼ â†’ ì˜¤ë¥¸ìª½ íœ˜ì–´ì„œ ì§„í–‰")
                    
                    elif right < 20:
                        soft_turn_left()
                        print("ì˜¤ë¥¸ìª½ì— ì¥ì• ë¬¼ â†’ ì™¼ìª½ íœ˜ì–´ì„œ ì§„í–‰")

                    elif box_center_x < image_width // 2 - 40:
                        #if not obstacle_avoidance():
                            soft_turn_left()
                            print("ëª©í‘œê°€ ì™¼ìª½ì— ìˆìŒ")
                            last_state = "left"
                    elif box_center_x > image_width // 2 + 40:
                        #if not obstacle_avoidance():
                            soft_turn_right()
                            last_state = "right"
                            print("ëª©í‘œê°€ ì˜¤ë¥¸ìª½ì— ìˆìŒ")
                    else :
                        #if not obstacle_avoidance():
                            move_forward()
                            print("ëª©í‘œê°€ ì •ë©´ì— ìˆìŒ")
                    
                    
                    # if front < 30:
                    #     stop_motors()
                    #     print("ëŒ€ìƒê³¼ ì ì •ê±°ë¦¬ ìœ ì§€")

                    text_x = box_x_min
                    text_y = box_y_min - 10 if box_y_min - 10 > 10 else box_y_min + 20 
                    text = f"{class_name}: {confidence:.2f}"
                    font_scale = 0.7
                    font_thickness = 2
                    cv2.putText(image, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), font_thickness)
                
            if not person_detected:
                if last_state == "left":
                    turn_left()
                    print("ë§ˆì§€ë§‰ ìœ„ì¹˜ ì™¼ìª½")
                elif last_state == "right":
                    turn_right()
                    print("ë§ˆì§€ë§‰ ìœ„ì¹˜ ì˜¤ë¥¸ìª½")
                # stop_motors()
                # print("ì‚¬ëŒì´ ê°ì§€ë˜ì§€ ì•ŠìŒ, ì •ì§€")

            cv2.imshow('Object Detection Result', image)
                        
    except KeyboardInterrupt:
        print("\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. (Ctrl+C ê°ì§€)")
    except Exception as e:
        print(f"ğŸš¨ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ ë°œìƒ: {e}")
    finally:
        try:
            if 'camera' in locals() and camera.started:
                camera.stop()
                print("âœ… Picamera2ê°€ ì„±ê³µì ìœ¼ë¡œ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ğŸš¨ ê²½ê³ : Picamera2 ì¤‘ì§€ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        cv2.destroyAllWindows()


if __name__ == '__main__':
    main()
