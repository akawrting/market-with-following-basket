import cv2
from picamera2 import Picamera2
from libcamera import Transform
from gpiozero import PWMOutputDevice, DigitalOutputDevice, DistanceSensor, RGBLED, Button
from time import sleep
import asyncio
import websockets
import json
import os
import threading

# === Í∏ÄÎ°úÎ≤å Î≥ÄÏàò ===
event_loop = None
button_event_queue = asyncio.Queue()

# === Î≤ÑÌäº Ï¥àÍ∏∞Ìôî ===
button = Button(15)  # GPIO 15Ïóê Î≤ÑÌäº Ïó∞Í≤∞

# === Î≤ÑÌäº Ïù¥Î≤§Ìä∏ Ï≤òÎ¶¨ Ìï®Ïàò ===
def on_button_pressed():
    global event_loop
    if event_loop:
        asyncio.run_coroutine_threadsafe(button_event_queue.put("pressed"), event_loop)

# Î≤ÑÌäº Ïù¥Î≤§Ìä∏ Ìï∏Îì§Îü¨ Ïó∞Í≤∞
button.when_pressed = on_button_pressed

# === Î≤ÑÌäº Ïù¥Î≤§Ìä∏ Ï≤òÎ¶¨ ÏΩîÎ£®Ìã¥ ===
async def handle_button_events():
    global current_state, autonomous_task
    while True:
        event = await button_event_queue.get()
        if event == "pressed":
            if current_state == "run":
                current_state = "stop"
                print("Î≤ÑÌäºÏúºÎ°ú Ï£ºÌñâ Ï†ïÏßÄ")
                if autonomous_task:
                    autonomous_task.cancel()
                stop_motors()
                rgbled.color = (1, 0, 0)  # Îπ®Í∞ÑÏÉâ
            elif current_state == "stop":
                current_state = "run"
                print("Î≤ÑÌäºÏúºÎ°ú Ï£ºÌñâ ÏãúÏûë")
                rgbled.color = (0, 1, 0)  # Ï¥àÎ°ùÏÉâ
                if autonomous_task:
                    autonomous_task.cancel()
                autonomous_task = asyncio.create_task(autonomous_driving())



# ÏõπÏÜåÏºì ÏÑúÎ≤Ñ Ï£ºÏÜå (ÎÖ∏Ìä∏Î∂ÅÏùò IP Ï£ºÏÜåÏôÄ Ìè¨Ìä∏)
SERVER_IP = "192.168.137.1"  # ÎÖ∏Ìä∏Î∂ÅÏùò Ïã§Ï†ú IP Ï£ºÏÜåÎ°ú Î≥ÄÍ≤Ω
SERVER_PORT = 8989
WEBSOCKET_SERVER_URL = f"ws://{SERVER_IP}:{SERVER_PORT}"

rgbled = RGBLED(red=5, green=6, blue=13, active_high=True) 

# === GPIO ÌïÄ ÏÑ§Ï†ï ===
PWMA = PWMOutputDevice(18)
AIN1 = DigitalOutputDevice(22) #Ïôº Î∞îÌÄ¥ ÌõÑÏßÑ
AIN2 = DigitalOutputDevice(27) #Ïôº Î∞îÌÄ¥ Ï†ÑÏßÑ
PWMB = PWMOutputDevice(23)
BIN1 = DigitalOutputDevice(25) #Ïò§Î•∏ Î∞îÌÄ¥ ÌõÑÏßÑ
BIN2 = DigitalOutputDevice(24) #Ïò§Î•∏ Î∞îÌÄ¥ Ï†ÑÏßÑ

# === Ï¥àÏùåÌåå ÏÑºÏÑú ÏÑ§Ï†ï ===
front_sensor = DistanceSensor(echo=10, trigger=9, max_distance=2.0)
left_sensor = DistanceSensor(echo=17, trigger=4, max_distance=2.0)
right_sensor = DistanceSensor(echo=8, trigger=7, max_distance=2.0)

# === ÏÉÅÌÉú Î≥ÄÏàò ===
current_state = "stop"  # Í∏∞Î≥∏ ÏÉÅÌÉúÎäî Ï†ïÏßÄ
autonomous_task = None  # ÏûêÏú®Ï£ºÌñâ ÏûëÏóÖ Ï∂îÏ†Å
last_state = "stop"  # ÎßàÏßÄÎßâ ÏÉÅÌÉú Ï∂îÏ†Å

# === Î™®ÌÑ∞ Ï†úÏñ¥ Ìï®Ïàò ===
def stop_motors():
    PWMA.value = 0.0
    PWMB.value = 0.0

def move_forward():
    AIN1.value, AIN2.value = 0, 1
    BIN1.value, BIN2.value = 0, 1
    PWMA.value = 1
    PWMB.value = 1

def turn_left():
    AIN1.value, AIN2.value = 1, 0
    BIN1.value, BIN2.value = 0, 1
    PWMA.value = 0.6
    PWMB.value = 0.6

def turn_right():
    AIN1.value, AIN2.value = 0, 1
    BIN1.value, BIN2.value = 1, 0
    PWMA.value = 0.6
    PWMB.value = 0.6

def soft_turn_left():
    AIN1.value, AIN2.value = 0, 0
    BIN1.value, BIN2.value = 0, 1
    PWMA.value = 1
    PWMB.value = 1

def soft_turn_right():
    AIN1.value, AIN2.value = 0, 1
    BIN1.value, BIN2.value = 0, 0
    PWMA.value = 1
    PWMB.value = 1


classNames = {0: 'background',
              1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus',
              7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant',
              13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat',
              18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear',
              24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag',
              32: 'tie', 33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard',
              37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove',
              41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle',
              46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon',
              51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange',
              56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut',
              61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed',
              67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse',
              75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven',
              80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock',
              86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', 90: 'toothbrush'}

def id_class_name(class_id, classes):
    return classes.get(class_id, "Unknown")

async def autonomous_driving():
    camera = Picamera2()
    camera.configure(camera.create_preview_configuration(
        main={"format": 'XRGB8888', "size": (640, 480)},
        transform=Transform(hflip=1, vflip=1) # ÏàòÌèâ, ÏàòÏßÅ Îí§ÏßëÍ∏∞ ÎèôÏãúÏóê Ï†ÅÏö© (180ÎèÑ ÌöåÏ†Ñ Ìö®Í≥º)
    ))
    
    try:
        camera.start()
        print("‚úÖ Picamera2Í∞Ä ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏãúÏûëÎêòÏóàÏäµÎãàÎã§.")
    except Exception as e:
        print(f"üö®üö®üö® ÏóêÎü¨: Picamera2Î•º ÏãúÏûëÌï† Ïàò ÏóÜÏäµÎãàÎã§! üö®üö®üö®")
        print(f"  - ÏóêÎü¨ Î©îÏãúÏßÄ: {e}")
        print("  1. Ïπ¥Î©îÎùº Î™®ÎìàÏù¥ Ï†úÎåÄÎ°ú Ïó∞Í≤∞ÎêòÏñ¥ ÏûàÎÇòÏöî?")
        print("  2. 'sudo raspi-config'ÏóêÏÑú Ïπ¥Î©îÎùº ÏòµÏÖòÏù¥ ÌôúÏÑ±ÌôîÎêòÏñ¥ ÏûàÎÇòÏöî?")
        print("  3. Îã§Î•∏ ÌîÑÎ°úÍ∑∏Îû®Ïù¥ Ïπ¥Î©îÎùºÎ•º ÏÇ¨Ïö©ÌïòÍ≥† ÏûàÏßÄÎäî ÏïäÎÇòÏöî?")
        print("  4. ÎùºÏ¶àÎ≤†Î¶¨ ÌååÏù¥Î•º Ïû¨Î∂ÄÌåÖÌï¥Î≥¥ÏÖ®ÎÇòÏöî?")
        return

    try:
        model = cv2.dnn.readNetFromTensorflow('/home/robot/market-with-following-basket/tracking/models/frozen_inference_graph.pb',
                                      '/home/robot/market-with-following-basket/tracking/models/ssd_mobilenet_v2_coco_2018_03_29.pbtxt')
        
        if model.empty():
            print("üö® ÏóêÎü¨: DNN Î™®Îç∏ÏùÑ Î°úÎìúÌï† Ïàò ÏóÜÏäµÎãàÎã§. ÌååÏùº Í≤ΩÎ°úÏôÄ ÌååÏùº ÏÜêÏÉÅ Ïó¨Î∂ÄÎ•º ÌôïÏù∏ÌïòÏÑ∏Ïöî.")
            return
        last_state = "stop"
        while current_state == "run":
            keyValue = cv2.waitKey(1)
        
            if keyValue == ord('q') :
                break
            
            image = camera.capture_array()
            image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)
            
            image_height, image_width, _ = image.shape

            model.setInput(cv2.dnn.blobFromImage(image, size=(300, 300), swapRB=True))
            output = model.forward()

            person_detected = False
            
            front = front_sensor.distance * 100
            left = left_sensor.distance * 100
            right = right_sensor.distance * 100
            print(f"Í±∞Î¶¨ - Ï†ïÎ©¥: {front:.1f}cm, ÏôºÏ™Ω: {left:.1f}cm, Ïò§Î•∏Ï™Ω: {right:.1f}cm")

            for detection in output[0, 0, :, :]:
                confidence = detection[2]
                class_id = int(detection[1])
                
                if confidence > .5 and class_id == 1: # Ïã†Î¢∞ÎèÑÍ∞Ä 0.5 Ïù¥ÏÉÅÏù¥Í≥†, ÌÅ¥ÎûòÏä§ IDÍ∞Ä 1 (ÏÇ¨Îûå)Ïù∏ Í≤ΩÏö∞
                    class_name=id_class_name(class_id,classNames)

                    person_detected = True

                    box_x_min = int(detection[3] * image_width)
                    box_y_min = int(detection[4] * image_height)
                    box_x_max = int(detection[5] * image_width)
                    box_y_max = int(detection[6] * image_height)
                    box_center_x = int((box_x_min + box_x_max) / 2)

                    cv2.rectangle(image, (box_x_min, box_y_min), (box_x_max, box_y_max), (0, 0, 200), thickness=2)
                    cv2.line(image, (box_center_x, box_y_min), (box_center_x, box_y_max), (200, 0, 0), thickness=2)
                    print(f"box_y_min: {box_y_min}, box_y_max: {box_y_max}")
                          
                    if box_y_min < 50:
                        stop_motors()
                        print("ÎåÄÏÉÅÍ≥º Ï†ÅÏ†ïÍ±∞Î¶¨ Ïú†ÏßÄ")
                        rgbled.color = (0, 1, 0)  # Ï¥àÎ°ùÏÉâ
                    
                    elif left < 20:
                        soft_turn_right()
                        print("ÏôºÏ™ΩÏóê Ïû•Ïï†Î¨º ‚Üí Ïò§Î•∏Ï™Ω ÌúòÏñ¥ÏÑú ÏßÑÌñâ")
                    
                    elif right < 20:
                        soft_turn_left()
                        print("Ïò§Î•∏Ï™ΩÏóê Ïû•Ïï†Î¨º ‚Üí ÏôºÏ™Ω ÌúòÏñ¥ÏÑú ÏßÑÌñâ")

                    elif box_center_x < image_width // 2 - 40:
                        #if not obstacle_avoidance():
                            soft_turn_left()
                            print("Î™©ÌëúÍ∞Ä ÏôºÏ™ΩÏóê ÏûàÏùå")
                            rgbled.color = (0, 1, 0)  # Ï¥àÎ°ùÏÉâ
                            last_state = "left"
                    elif box_center_x > image_width // 2 + 40:
                        #if not obstacle_avoidance():
                            soft_turn_right()
                            last_state = "right"
                            rgbled.color = (0, 1, 0)  # Ï¥àÎ°ùÏÉâ
                            print("Î™©ÌëúÍ∞Ä Ïò§Î•∏Ï™ΩÏóê ÏûàÏùå")
                    else :
                        #if not obstacle_avoidance():
                            move_forward()
                            print("Î™©ÌëúÍ∞Ä Ï†ïÎ©¥Ïóê ÏûàÏùå")
                            rgbled.color = (0, 1, 0)  # Ï¥àÎ°ùÏÉâ
                            sleep(1)
                    

                    text_x = box_x_min
                    text_y = box_y_min - 10 if box_y_min - 10 > 10 else box_y_min + 20 
                    text = f"{class_name}: {confidence:.2f}"
                    font_scale = 0.7
                    font_thickness = 2
                    cv2.putText(image, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), font_thickness)
                
            if not person_detected:
                if last_state == "left":
                    turn_left()
                    print("ÎßàÏßÄÎßâ ÏúÑÏπò ÏôºÏ™Ω")
                    rgbled.color = (1, 0, 0)
                    
                elif last_state == "right":
                    turn_right()
                    print("ÎßàÏßÄÎßâ ÏúÑÏπò Ïò§Î•∏Ï™Ω")
                    rgbled.color = (1, 0, 0)
                # stop_motors()
                # print("ÏÇ¨ÎûåÏù¥ Í∞êÏßÄÎêòÏßÄ ÏïäÏùå, Ï†ïÏßÄ")

            cv2.imshow('Object Detection Result', image)
            await asyncio.sleep(0.1)
                        
    except KeyboardInterrupt:
        print("\nÌîÑÎ°úÍ∑∏Îû®ÏùÑ Ï¢ÖÎ£åÌï©ÎãàÎã§. (Ctrl+C Í∞êÏßÄ)")
    except Exception as e:
        print(f"üö® ÏòàÏÉÅÏπò Î™ªÌïú ÏóêÎü¨ Î∞úÏÉù: {e}")
    except asyncio.CancelledError:
        # CancelledError Î∞úÏÉù Ïãú Ï†ïÎ¶¨ ÏûëÏóÖ
        print("ÏûêÏú®Ï£ºÌñâ ÏûëÏóÖ Ï∑®ÏÜåÎê®")
        stop_motors()
        camera.close()
    finally:
        try:
            if 'camera' in locals() and camera.started:
                camera.stop()
                print("‚úÖ Picamera2Í∞Ä ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Ï§ëÏßÄÎêòÏóàÏäµÎãàÎã§.")
        except Exception as e:
            print(f"üö® Í≤ΩÍ≥†: Picamera2 Ï§ëÏßÄ Ï§ë ÏóêÎü¨ Î∞úÏÉù: {e}")
        cv2.destroyAllWindows()


# === WebSocket Ï≤òÎ¶¨ ===
async def handle_websocket():
    print(f"ÏõπÏÜåÏºì ÏÑúÎ≤ÑÏóê Ïó∞Í≤∞ Ï§ë")
    global current_state, autonomous_task

    while True:
        try:
            async with websockets.connect("ws://192.168.137.1:8989") as websocket:
                print("ÏõπÏÜåÏºì ÏÑúÎ≤ÑÏóê Ïó∞Í≤∞ÎêòÏóàÏäµÎãàÎã§.")
                while True:
                    message = await websocket.recv()
                    data = json.loads(message)
                    command = data.get("command")

                    if command == "run" and current_state != "run":
                        current_state = "run"
                        if autonomous_task:
                            autonomous_task.cancel()
                        autonomous_task = asyncio.create_task(autonomous_driving())

                    elif command == "stop" and current_state != "stop":
                        current_state = "stop"
                        if autonomous_task:
                            autonomous_task.cancel()
                        stop_motors()
                        rgbled.color = (0, 0, 0)
        except Exception as e:
            print(f"WebSocket Error: {e}")
        await asyncio.sleep(5)

# === Ïù¥Î≤§Ìä∏ Î£®ÌîÑ Ïä§Î†àÎìú ===
def start_event_loop():
    global event_loop
    event_loop = asyncio.new_event_loop()
    asyncio.set_event_loop(event_loop)
    event_loop.run_until_complete(asyncio.gather(
        handle_button_events(),
        handle_websocket()
    ))

# === Î©îÏù∏ ===
if __name__ == "__main__":
    # Î≥ÑÎèÑÏùò Ïä§Î†àÎìúÏóêÏÑú asyncio Î£®ÌîÑ Ïã§Ìñâ
    loop_thread = threading.Thread(target=start_event_loop, daemon=True)
    loop_thread.start()

    try:
        while True:
            pass  # Î©îÏù∏ Î£®ÌîÑÎ•º Ïú†ÏßÄÌïòÍ∏∞ ÏúÑÌïú ÏûêÎ¶¨ÌëúÏãúÏûê
    except KeyboardInterrupt:
        print("ÌîÑÎ°úÍ∑∏Îû® Ï¢ÖÎ£å")